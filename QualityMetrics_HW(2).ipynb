{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/master/06-model-evaluation/QualityMetrics_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij_zY4soDF2Z"
      },
      "source": [
        "# Cross-validation riddle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUCsY5OlDJPl"
      },
      "source": [
        "Here's a small example of cross-validation done wrongly. Can you spot the problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mSUzkXsC-R4H"
      },
      "outputs": [],
      "source": [
        "# Some imports...\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib as mpl\n",
        "\n",
        "cmap = mpl.colors.ListedColormap(['#992622', '#005AAA'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyDp3Xc_DaDM"
      },
      "source": [
        "**Plan:**\n",
        "\n",
        "- Let's create a binary classification dataset where targets are completely independent from the features\n",
        "  - *(i.e. no model could ever predict them well)*\n",
        "- We'll do some simple feature selection\n",
        "- And cross-validate a model on this data\n",
        "\n",
        "**Q:** what accuracy do we expect (classes are even)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHx51DKP8Rcf"
      },
      "source": [
        "We'll start from writing a class to select the best features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rRNmKZJJ8W7x"
      },
      "outputs": [],
      "source": [
        "class FeatureSelector:\n",
        "  def __init__(self, num_features):\n",
        "    self.n = num_features # number of best features to select\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Select features that describe the targets best, i.e. have\n",
        "    # highest correlation with them:\n",
        "    covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0)\n",
        "    self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
        "\n",
        "  def transform(self, X):\n",
        "    return X[:,self.best_feature_ids]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mu9gHgNBk_V",
        "outputId": "b6948929-8f6f-470c-bbb7-47f60e072d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.9299999999999999\n"
          ]
        }
      ],
      "source": [
        "num_features_total = 1000\n",
        "num_features_best = 100\n",
        "\n",
        "N = 100\n",
        "\n",
        "# Dataset generation\n",
        "X = np.random.normal(size=(N, num_features_total))\n",
        "y = np.random.randint(2, size=N)\n",
        "\n",
        "# Feature selection:\n",
        "X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
        "\n",
        "# Simple classification model\n",
        "model = LinearSVC()\n",
        "\n",
        "# Estimatin accuracy using cross-validation:\n",
        "cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "print(f\"CV score is {cv_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tv4iURh4PcPB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5nVduK-PZd1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAsiXZHfSPU0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afadN3ZVFKjF"
      },
      "source": [
        "What's going on?! Why accuracy is so high?\n",
        "\n",
        "Maybe it just happened by chance? Let's repeat this experiment many times and histogram the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QDbOMXnuC6uw",
        "outputId": "935b2143-c62a-48f8-aa78-20ccc5d5bcc3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "num_features_total = 1000\n",
        "num_features_best = 100\n",
        "\n",
        "N = 100\n",
        "def experiment():\n",
        "  # Dataset generation\n",
        "  X = np.random.normal(size=(N, num_features_total))\n",
        "  y = np.random.randint(2, size=N)\n",
        "\n",
        "  # Feature selection:\n",
        "  X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
        "\n",
        "  # Simple classification model\n",
        "  model = LinearSVC()\n",
        "\n",
        "  # Estimatin accuracy using cross-validation:\n",
        "  return cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "\n",
        "results = [experiment() for _ in range(100)]\n",
        "plt.hist(results, bins=10);"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EdAIzH13PJZ8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMYRjjqOLB5Z"
      },
      "source": [
        "## Task 1 (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bLaEypoF5pb"
      },
      "source": [
        "Explain why the estimated model accuracy is not 50% on a dataset where targets were generated **independently from the features (!!!)**.\n",
        "\n",
        "Find and fix the problem (don't change the dataset generation or its parameters - `num_features_total`, `num_features_best`, `N`).\n",
        "\n",
        "*Hint: the problem is in the overall logic, and not a bug in the code.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$\\color{magenta}{\\text{Explanation: here we see that cross-validation is done after choosing the most correlating features; as a result, we fit our model by the whole set of samples, }}$\n",
        "\n",
        "$\\color{magenta}{\\text{after that we divide it into train and test parts \n",
        "which suit chosen features very well, that's why we have such a huge score. We could fix it by selecting high-correlated features only within train set.    }}$\n",
        "\n",
        "$\\color{magenta}{\\text{To do it, we just introduce pipeline with FeatureSelector as a parameter, it provides imlementation of function only to training folds. The code is below.}}$            \n",
        "\n"
      ],
      "metadata": {
        "id": "FWn8dSAtDZCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureSelector:\n",
        "  def __init__(self, num_features):\n",
        "    self.n = num_features # number of best features to select\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Select features that describe the targets best, i.e. have\n",
        "    # highest correlation with them:\n",
        "    covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0)\n",
        "    self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
        " \n",
        "  def transform(self, X):\n",
        "    return X[:,self.best_feature_ids]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ],
      "metadata": {
        "id": "DD3LHlja-aNM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EfT36WPTLyqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "8cb7c963-63bb-433d-8a31-3e935566f1b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.pipeline import make_pipeline \n",
        "num_features_total = 1000\n",
        "num_features_best = 100\n",
        "\n",
        "N = 100\n",
        "def experiment():\n",
        "  # Dataset generation\n",
        "  X = np.random.normal(size=(N, num_features_total))\n",
        "  y = np.random.randint(2, size=N)\n",
        "\n",
        "  # Feature selection:\n",
        "  X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
        "\n",
        "  # Simple classification model\n",
        "  model = make_pipeline(\n",
        "      FeatureSelector(num_features_best),\n",
        "      LinearSVC()\n",
        "\n",
        "      )\n",
        "      \n",
        "\n",
        "  # Estimatin accuracy using cross-validation:\n",
        "  return cross_val_score(model, X, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
        "\n",
        "results = [experiment() for _ in range(100)]\n",
        "plt.hist(results, bins=10);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8qqWFUKadL8"
      },
      "source": [
        "## Task 2 (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_WMXIBUadL8"
      },
      "source": [
        "Let's come back to Task 3 of Data Handling HW.\n",
        "Build a model with KNeighborsClassifier to get a higher accuracy on 5-fold Cross Validation than you achieve using your previosly fitted model (you can just copy the params from the previous notebook). \n",
        "\n",
        "Use `sklearn.model_selection.GridSearchCV` to find best parameters.  You may check the parameters'  description as follows:\n",
        "``` python\n",
        "help(KNeighborsClassifier)\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(KNeighborsClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4GDnkLof7qi",
        "outputId": "7bed5a4e-c246-4b44-f5ba-25345f54bc30"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
            "\n",
            "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
            " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |  \n",
            " |  Classifier implementing the k-nearest neighbors vote.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <classification>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  n_neighbors : int, default=5\n",
            " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
            " |  \n",
            " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
            " |      Weight function used in prediction.  Possible values:\n",
            " |  \n",
            " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
            " |        are weighted equally.\n",
            " |      - 'distance' : weight points by the inverse of their distance.\n",
            " |        in this case, closer neighbors of a query point will have a\n",
            " |        greater influence than neighbors which are further away.\n",
            " |      - [callable] : a user-defined function which accepts an\n",
            " |        array of distances, and returns an array of the same shape\n",
            " |        containing the weights.\n",
            " |  \n",
            " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
            " |      Algorithm used to compute the nearest neighbors:\n",
            " |  \n",
            " |      - 'ball_tree' will use :class:`BallTree`\n",
            " |      - 'kd_tree' will use :class:`KDTree`\n",
            " |      - 'brute' will use a brute-force search.\n",
            " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
            " |        based on the values passed to :meth:`fit` method.\n",
            " |  \n",
            " |      Note: fitting on sparse input will override the setting of\n",
            " |      this parameter, using brute force.\n",
            " |  \n",
            " |  leaf_size : int, default=30\n",
            " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
            " |      speed of the construction and query, as well as the memory\n",
            " |      required to store the tree.  The optimal value depends on the\n",
            " |      nature of the problem.\n",
            " |  \n",
            " |  p : int, default=2\n",
            " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
            " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
            " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
            " |  \n",
            " |  metric : str or callable, default='minkowski'\n",
            " |      The distance metric to use for the tree.  The default metric is\n",
            " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
            " |      metric. For a list of available metrics, see the documentation of\n",
            " |      :class:`~sklearn.metrics.DistanceMetric`.\n",
            " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
            " |      must be square during fit. X may be a :term:`sparse graph`,\n",
            " |      in which case only \"nonzero\" elements may be considered neighbors.\n",
            " |  \n",
            " |  metric_params : dict, default=None\n",
            " |      Additional keyword arguments for the metric function.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      The number of parallel jobs to run for neighbors search.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |      Doesn't affect :meth:`fit` method.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : array of shape (n_classes,)\n",
            " |      Class labels known to the classifier\n",
            " |  \n",
            " |  effective_metric_ : str or callble\n",
            " |      The distance metric used. It will be same as the `metric` parameter\n",
            " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
            " |      'minkowski' and `p` parameter set to 2.\n",
            " |  \n",
            " |  effective_metric_params_ : dict\n",
            " |      Additional keyword arguments for the metric function. For most metrics\n",
            " |      will be same with `metric_params` parameter, but may also contain the\n",
            " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
            " |      'minkowski'.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_samples_fit_ : int\n",
            " |      Number of samples in the fitted data.\n",
            " |  \n",
            " |  outputs_2d_ : bool\n",
            " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
            " |      otherwise True.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
            " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
            " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
            " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
            " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
            " |  \n",
            " |  .. warning::\n",
            " |  \n",
            " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
            " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
            " |     but different labels, the results will depend on the ordering of the\n",
            " |     training data.\n",
            " |  \n",
            " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> X = [[0], [1], [2], [3]]\n",
            " |  >>> y = [0, 0, 1, 1]\n",
            " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
            " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
            " |  >>> neigh.fit(X, y)\n",
            " |  KNeighborsClassifier(...)\n",
            " |  >>> print(neigh.predict([[1.1]]))\n",
            " |  [0]\n",
            " |  >>> print(neigh.predict_proba([[0.9]]))\n",
            " |  [[0.666... 0.333...]]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      KNeighborsClassifier\n",
            " |      sklearn.neighbors._base.KNeighborsMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.neighbors._base.NeighborsBase\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y)\n",
            " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
            " |          Training data.\n",
            " |      \n",
            " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
            " |          Target values.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : KNeighborsClassifier\n",
            " |          The fitted k-nearest neighbors classifier.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict the class labels for the provided data.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
            " |          Test samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
            " |          Class labels for each data sample.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Return probability estimates for the test data X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
            " |          Test samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
            " |          The class probabilities of the input samples. Classes are ordered\n",
            " |          by lexicographic order.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |  \n",
            " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
            " |      Find the K-neighbors of a point.\n",
            " |      \n",
            " |      Returns indices of and distances to the neighbors of each point.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |      \n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors required for each sample. The default is the\n",
            " |          value passed to the constructor.\n",
            " |      \n",
            " |      return_distance : bool, default=True\n",
            " |          Whether or not to return the distances.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Array representing the lengths to points, only present if\n",
            " |          return_distance=True.\n",
            " |      \n",
            " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Indices of the nearest points in the population matrix.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      In the following example, we construct a NearestNeighbors\n",
            " |      class from an array representing our data set and ask who's\n",
            " |      the closest point to [1,1,1]\n",
            " |      \n",
            " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
            " |      >>> neigh.fit(samples)\n",
            " |      NearestNeighbors(n_neighbors=1)\n",
            " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
            " |      (array([[0.5]]), array([[2]]))\n",
            " |      \n",
            " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
            " |      element is at distance 0.5 and is the third element of samples\n",
            " |      (indexes start at 0). You can also query for multiple points:\n",
            " |      \n",
            " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
            " |      >>> neigh.kneighbors(X, return_distance=False)\n",
            " |      array([[1],\n",
            " |             [2]]...)\n",
            " |  \n",
            " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
            " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |          For ``metric='precomputed'`` the shape should be\n",
            " |          (n_queries, n_indexed). Otherwise the shape should be\n",
            " |          (n_queries, n_features).\n",
            " |      \n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors for each sample. The default is the value\n",
            " |          passed to the constructor.\n",
            " |      \n",
            " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
            " |          Type of returned matrix: 'connectivity' will return the\n",
            " |          connectivity matrix with ones and zeros, in 'distance' the\n",
            " |          edges are distances between points, type of distance\n",
            " |          depends on the selected metric parameter in\n",
            " |          NearestNeighbors class.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
            " |          `n_samples_fit` is the number of samples in the fitted data.\n",
            " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
            " |          The matrix is of CSR format.\n",
            " |      \n",
            " |      See Also\n",
            " |      --------\n",
            " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
            " |          of Neighbors for points in X.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      >>> X = [[0], [3], [1]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
            " |      >>> neigh.fit(X)\n",
            " |      NearestNeighbors(n_neighbors=2)\n",
            " |      >>> A = neigh.kneighbors_graph(X)\n",
            " |      >>> A.toarray()\n",
            " |      array([[1., 0., 1.],\n",
            " |             [0., 1., 1.],\n",
            " |             [1., 0., 1.]])\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YtEAc-cEadL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291ee142-9ee9-4592-a4ff-418e13a7245e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:08:53--  https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60302 (59K) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "\rtrain.csv             0%[                    ]       0  --.-KB/s               \rtrain.csv           100%[===================>]  58.89K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-11-01 08:08:54 (17.7 MB/s) - ‘train.csv’ saved [60302/60302]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/HSE-LAMBDA/MLDM-2022/main/01-intro/train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gVcsmKNAadL9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "data = pd.read_csv(\"train.csv\", index_col='PassengerId')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dDfhmIdXadL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "29f71e87-f16b-4a04-efd8-9c1839d388dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Survived  Pclass  \\\n",
              "PassengerId                     \n",
              "1                   0       3   \n",
              "2                   1       1   \n",
              "3                   1       3   \n",
              "4                   1       1   \n",
              "5                   0       3   \n",
              "\n",
              "                                                          Name     Sex   Age  \\\n",
              "PassengerId                                                                    \n",
              "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
              "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
              "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
              "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
              "5                                     Allen, Mr. William Henry    male  35.0   \n",
              "\n",
              "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
              "PassengerId                                                          \n",
              "1                1      0         A/5 21171   7.2500   NaN        S  \n",
              "2                1      0          PC 17599  71.2833   C85        C  \n",
              "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "4                1      0            113803  53.1000  C123        S  \n",
              "5                0      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b97d46df-ace7-4087-91e0-ad88f31878d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b97d46df-ace7-4087-91e0-ad88f31878d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b97d46df-ace7-4087-91e0-ad88f31878d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b97d46df-ace7-4087-91e0-ad88f31878d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "def feature_selection_and_preprocessing(dataset):\n",
        "  \n",
        "  features = dataset[[\"Fare\", 'Pclass']].copy()\n",
        "  return features\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "data = pd.read_csv(\"train.csv\", index_col='PassengerId')\n",
        "data_train = data.iloc[:-100]\n",
        "data_test = data.iloc[-100:]\n",
        "\n",
        "X = feature_selection_and_preprocessing(data.drop('Survived', axis=1))\n",
        "y = data['Survived']\n",
        "\n",
        "cv_score = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1).mean()\n",
        "print(f\"CV score is {cv_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw7Nh4w_M7TT",
        "outputId": "acd83602-366f-4ae8-cbf5-57cd6b48ce3a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.6610319502856067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROEUSemyPBtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_grid = {'n_neighbors': np.arange(1,20), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': np.arange(1,20)}\n",
        "gscv = GridSearchCV(model, param_grid, scoring='accuracy', cv=kf, n_jobs=-1)\n",
        "\n",
        "gscv.fit(X, y)\n",
        "\n",
        "print(gscv.best_params_)\n",
        "print(gscv.best_score_)"
      ],
      "metadata": {
        "id": "EU-5w1Aeeax0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt6Ll_AKgh8B",
        "outputId": "6840d7e7-a1fe-42e3-fbd8-2edcdf43cd32"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzvdE6NmjiS5"
      },
      "execution_count": 48,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}